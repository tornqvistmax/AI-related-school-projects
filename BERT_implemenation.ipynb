{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-modellen",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgV1572ZEwOr"
      },
      "source": [
        "#BERT\n",
        "Vad görs i denna notebook?\n",
        "- BERT modell hämtas från TensorFlow Hub\n",
        "- Twitter data hämtas från NLTK Twitter Corpus\n",
        "- BERT kombineras med en klassificerare för sentiment analys\n",
        "- Modellen tränas och BERT fine-tuneas\n",
        "- Modellen sparas och används för att klassificera tweets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC0q6Bar3cYr"
      },
      "source": [
        "Huvudsaklig: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/classify_text_with_bert.ipynb#scrollTo=6IwI_2bcIeX8\n",
        "\n",
        "Utöver https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb#scrollTo=7wzwke0sxS6W\n",
        "så är denna colab till stora delar inspirerad/guidad av: https://pypi.org/project/bert-for-tf2/ för förenkling av importeringar osv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ewY1x39PraJ"
      },
      "source": [
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK7HkDurpwuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45a73437-f105-486a-bc1d-e9331268cf25"
      },
      "source": [
        "!pip install -q tensorflow-text\n",
        "!pip install -q tf-models-official\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.4MB 13.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 17.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 44.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 64.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 59.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 16.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 55.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.6MB 83kB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.9MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T81mFf6UPzKv"
      },
      "source": [
        "#Sentiment140\n",
        "Importing the dataset and preparing it for use in the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jjisu0eIm4hA"
      },
      "source": [
        "---\n",
        "Uploads a zip file containing the Sentiment140 dataset to Google colab. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0KG-b8itJlo",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "47a72fb5-63d0-40c6-b1d2-167a4204bef6"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c76aed31-0ca2-4e92-be2b-34e815ce1e86\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c76aed31-0ca2-4e92-be2b-34e815ce1e86\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving trainingdata.zip to trainingdata.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fToCXrVfjwCR",
        "outputId": "3f2eb37c-f70c-4816-f045-f203b0e02016"
      },
      "source": [
        "!unzip trainingdata.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  trainingdata.zip\n",
            "  inflating: training.1600000.processed.noemoticon.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53tMDxR9nGsx"
      },
      "source": [
        "Reads the dataset. Dataset contains 4 and 0 labels. 0 represents negative and 4 positive. 4 label is converted to 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ROjQ0FWHj-hj",
        "outputId": "40411b08-b32a-452e-8dca-ba55eed9c950"
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('training.1600000.processed.noemoticon.csv',encoding='latin-1',usecols=[0,5],names=['sentiment','text','text2','text3','text4','tweets'])\n",
        "\n",
        "df.head()\n",
        "\n",
        "df['sentiment'] = df['sentiment'].replace(4,1)\n",
        "tweetslist = df.values.tolist()\n",
        "random.shuffle(tweetslist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                             tweets\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf-8v1WCPwGD"
      },
      "source": [
        "#Building the model\n",
        "These are the methods used for building the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QhG7bOozJq"
      },
      "source": [
        "---\n",
        "Method for building the model itself and its layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puuQvfRPIcYp"
      },
      "source": [
        "def build_classifier_model(batch):\n",
        "\n",
        "  #Loads the pre-trained BERT-model and the corresponding preprocessor\n",
        "  tfhub_handle_encoder = hub.load('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3')\n",
        "  tfhub_handle_preprocess = hub.load(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1\")\n",
        "\n",
        "  #Builds the layers of the BERT-model\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='inputs',batch_size=batch)\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(1, activation='gelu', name='classifier')(net) \n",
        "  \n",
        "  return tf.keras.Model(inputs=text_input, outputs=net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XD0unUtpALb"
      },
      "source": [
        "Defines the loss function which in this case is binary crossentrpoy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glsi6AtWM0_8"
      },
      "source": [
        "def lossfunction():\n",
        "  return tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Yl8vTlkpQGX"
      },
      "source": [
        "Defines epochs and optimizer of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1_CaIkGPoMt"
      },
      "source": [
        "def define_epochs(trainingdata,e):\n",
        "  epochs = e\n",
        "  steps_per_epoch = tf.data.experimental.cardinality(trainingdata).numpy()\n",
        "  num_train_steps = steps_per_epoch * epochs\n",
        "  num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "  init_lr = 3e-5\n",
        "  optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                            num_train_steps=num_train_steps,\n",
        "                                            num_warmup_steps=num_warmup_steps,\n",
        "                                            optimizer_type='adamw')\n",
        "  return epochs, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp-QgWzLpfd7"
      },
      "source": [
        "Final compilation of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTdw5__KQgHp"
      },
      "source": [
        "def compile_model(optimizer, loss):\n",
        "  classifier_model.compile(optimizer=optimizer,\n",
        "                          loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Hay4QFoQdJx"
      },
      "source": [
        "#Execution of the cross-validation and corresponding  fine-tuning.\n",
        "This is the main body of code for the model.\n",
        "Firstly the final operations on the data are made  and the validation data is split from the rest of the data.\n",
        "Secondly the cross-validation is made which includes fine-tuning and evaluation of each of the *K* models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11tr2czMSJBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8cf3777-418d-4788-9bc1-f0043cea5de8"
      },
      "source": [
        "#Defines some basic parameters for the model. Number of epochs, Batch size of the input data and the K-value of the cross-validation\n",
        "NUM_OF_EPOCHS = 3\n",
        "K = 5\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "#Labelling for the evaluation. Not necessary for functionality.\n",
        "sentiment = ['Negative', 'Positive']\n",
        "\n",
        "#Splits data into X - exapmles, and y - labels. Also limits the data used to 5% of original dataset size.\n",
        "X = np.array([x[1] for x in tweetslist])\n",
        "y = np.array([x[0] for x in tweetslist])\n",
        "X, Xg, y, yg = train_test_split(X,y,train_size=0.05, test_size=0.95, stratify=y)\n",
        "\n",
        "#Splits the validation data from the main data and converts it into a Tensorflow dataset.\n",
        "X, Xval, y, yval = train_test_split(X,y,train_size=0.9,test_size=0.1,stratify=y)\n",
        "\n",
        "valdata = tf.data.Dataset.from_tensor_slices((Xval,yval))\n",
        "valdata = valdata.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "#Main cross-validation loop that is run K times\n",
        "skf = StratifiedKFold(shuffle=True,n_splits=K)\n",
        "n = 0\n",
        "for train, test in skf.split(X, y):\n",
        "\n",
        "  n += 1\n",
        "  print(n)\n",
        "  classifier_model = None\n",
        "\n",
        "  #Uses the indexes provided to make train and testsets and converts them into tensorflow datatsets\n",
        "  traindata = tf.data.Dataset.from_tensor_slices((X[train], y[train]))\n",
        "  testdata = tf.data.Dataset.from_tensor_slices((X[test], y[test]))\n",
        " \n",
        "  traindata = traindata.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  testdata = testdata.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "  #Builds model\n",
        "  classifier_model = build_classifier_model(BATCH_SIZE)\n",
        "\n",
        "  #Defines the rest of the necessary components. loss, pochs and optimizer\n",
        "  loss = lossfunction()\n",
        "  \n",
        "  epochs, optimizer = define_epochs(traindata,NUM_OF_EPOCHS)\n",
        "\n",
        "  compile_model(optimizer, loss)\n",
        "\n",
        "  #Displays the final model build including it's layers. Can be viewed in output below.\n",
        "  print(classifier_model.summary())\n",
        "  \n",
        "\n",
        "  #Fine-tunes the model\n",
        "  classifier_model.fit(x=traindata, epochs=epochs, validation_data=valdata) #callbacks=[cp_callback])  # Pass callback to training)\n",
        "\n",
        "  #Evaluation\n",
        "  #The model makes it's predictions on the test data.\n",
        "  predictions = classifier_model.predict(testdata)\n",
        "\n",
        "  #The Keras functional model gives predictions in the form of weights where all weights above 0.5 are considered to be of class 1 and the ones 0.5 and below are class 0.\n",
        "  predictions[predictions > 0.5] = 1\n",
        "  predictions[predictions <= 0.5] = 0\n",
        "\n",
        "  #Final evaluation\n",
        "  print(classification_report(y[test], predictions,target_names= sentiment))\n",
        "\n",
        "  #Saves the model\n",
        "  classifier_model.save('BERT' + str(n))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputs (InputLayer)             [(32,)]              0                                            \n",
            "__________________________________________________________________________________________________\n",
            "preprocessing (KerasLayer)      {'input_word_ids': ( 0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "BERT_encoder (KerasLayer)       {'encoder_outputs':  109482241   preprocessing[0][0]              \n",
            "                                                                 preprocessing[0][1]              \n",
            "                                                                 preprocessing[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (32, 768)            0           BERT_encoder[0][13]              \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (32, 1)              769         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 109,483,009\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "1800/1800 [==============================] - 1729s 951ms/step - loss: 0.5823 - val_loss: 0.5064\n",
            "Epoch 2/3\n",
            "1800/1800 [==============================] - 1713s 952ms/step - loss: 0.4882 - val_loss: 0.5760\n",
            "Epoch 3/3\n",
            "1800/1800 [==============================] - 1712s 951ms/step - loss: 0.4363 - val_loss: 0.5536\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.80      0.90      0.85      7200\n",
            "    Positive       0.88      0.78      0.83      7200\n",
            "\n",
            "    accuracy                           0.84     14400\n",
            "   macro avg       0.84      0.84      0.84     14400\n",
            "weighted avg       0.84      0.84      0.84     14400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 910). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 910). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputs (InputLayer)             [(32,)]              0                                            \n",
            "__________________________________________________________________________________________________\n",
            "preprocessing (KerasLayer)      {'input_word_ids': ( 0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "BERT_encoder (KerasLayer)       {'sequence_output':  109482241   preprocessing[0][0]              \n",
            "                                                                 preprocessing[0][1]              \n",
            "                                                                 preprocessing[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (32, 768)            0           BERT_encoder[0][13]              \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (32, 1)              769         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 109,483,009\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "1800/1800 [==============================] - 1733s 953ms/step - loss: 0.5858 - val_loss: 0.5333\n",
            "Epoch 2/3\n",
            "1800/1800 [==============================] - 1715s 953ms/step - loss: 0.4862 - val_loss: 0.5632\n",
            "Epoch 3/3\n",
            "1800/1800 [==============================] - 1716s 953ms/step - loss: 0.4359 - val_loss: 0.5637\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.80      0.89      0.84      7200\n",
            "    Positive       0.87      0.78      0.83      7200\n",
            "\n",
            "    accuracy                           0.83     14400\n",
            "   macro avg       0.84      0.83      0.83     14400\n",
            "weighted avg       0.84      0.83      0.83     14400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 910). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 910). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputs (InputLayer)             [(32,)]              0                                            \n",
            "__________________________________________________________________________________________________\n",
            "preprocessing (KerasLayer)      {'input_word_ids': ( 0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "BERT_encoder (KerasLayer)       {'encoder_outputs':  109482241   preprocessing[0][0]              \n",
            "                                                                 preprocessing[0][1]              \n",
            "                                                                 preprocessing[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (32, 768)            0           BERT_encoder[0][13]              \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (32, 1)              769         dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 109,483,009\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "1800/1800 [==============================] - 1732s 954ms/step - loss: 0.5872 - val_loss: 0.5369\n",
            "Epoch 2/3\n",
            "1800/1800 [==============================] - 1717s 954ms/step - loss: 0.4904 - val_loss: 0.5651\n",
            "Epoch 3/3\n",
            "1800/1800 [==============================] - 1716s 953ms/step - loss: 0.4393 - val_loss: 0.5768\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.81      0.88      0.84      7200\n",
            "    Positive       0.87      0.80      0.83      7200\n",
            "\n",
            "    accuracy                           0.84     14400\n",
            "   macro avg       0.84      0.84      0.84     14400\n",
            "weighted avg       0.84      0.84      0.84     14400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 910). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 910). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputs (InputLayer)             [(32,)]              0                                            \n",
            "__________________________________________________________________________________________________\n",
            "preprocessing (KerasLayer)      {'input_type_ids': ( 0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "BERT_encoder (KerasLayer)       {'encoder_outputs':  109482241   preprocessing[0][0]              \n",
            "                                                                 preprocessing[0][1]              \n",
            "                                                                 preprocessing[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (32, 768)            0           BERT_encoder[0][13]              \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (32, 1)              769         dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 109,483,009\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "1800/1800 [==============================] - 1735s 955ms/step - loss: 0.5839 - val_loss: 0.5216\n",
            "Epoch 2/3\n",
            "1800/1800 [==============================] - 1717s 954ms/step - loss: 0.4886 - val_loss: 0.5291\n",
            "Epoch 3/3\n",
            "1800/1800 [==============================] - 1716s 953ms/step - loss: 0.4349 - val_loss: 0.5590\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.81      0.89      0.85      7200\n",
            "    Positive       0.87      0.79      0.83      7200\n",
            "\n",
            "    accuracy                           0.84     14400\n",
            "   macro avg       0.84      0.84      0.84     14400\n",
            "weighted avg       0.84      0.84      0.84     14400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 910). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 910). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputs (InputLayer)             [(32,)]              0                                            \n",
            "__________________________________________________________________________________________________\n",
            "preprocessing (KerasLayer)      {'input_word_ids': ( 0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "BERT_encoder (KerasLayer)       {'encoder_outputs':  109482241   preprocessing[0][0]              \n",
            "                                                                 preprocessing[0][1]              \n",
            "                                                                 preprocessing[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (32, 768)            0           BERT_encoder[0][13]              \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (32, 1)              769         dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 109,483,009\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "1800/1800 [==============================] - 1730s 951ms/step - loss: 0.5826 - val_loss: 0.5540\n",
            "Epoch 2/3\n",
            "1800/1800 [==============================] - 1716s 954ms/step - loss: 0.4899 - val_loss: 0.5444\n",
            "Epoch 3/3\n",
            "1800/1800 [==============================] - 1716s 954ms/step - loss: 0.4375 - val_loss: 0.5506\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.81      0.89      0.85      7200\n",
            "    Positive       0.88      0.79      0.83      7200\n",
            "\n",
            "    accuracy                           0.84     14400\n",
            "   macro avg       0.84      0.84      0.84     14400\n",
            "weighted avg       0.84      0.84      0.84     14400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 910). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 910). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sEJjbWsu9R4"
      },
      "source": [
        "Code below this point concerns saving and loading of an already fine-tuned model and should not affect the results of the thesis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7USRuCUOeZv",
        "outputId": "f4d3af8d-f6ec-4ee1-a3fc-6b7fb4f3b3ec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg8g-3eEAQDK",
        "outputId": "07348157-0134-406a-ce43-5e827456c06b"
      },
      "source": [
        "!zip -r '/content/drive/MyDrive/BERT1.zip' '/content/BERT1'\n",
        "!zip -r '/content/drive/MyDrive/BERT2.zip' '/content/BERT2'\n",
        "!zip -r '/content/drive/MyDrive/BERT3.zip' '/content/BERT3'\n",
        "!zip -r '/content/drive/MyDrive/BERT4.zip' '/content/BERT4'\n",
        "!zip -r '/content/drive/MyDrive/BERT5.zip' '/content/BERT5'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/BERT1/ (stored 0%)\n",
            "  adding: content/BERT1/assets/ (stored 0%)\n",
            "  adding: content/BERT1/assets/vocab.txt (deflated 53%)\n",
            "  adding: content/BERT1/saved_model.pb (deflated 93%)\n",
            "  adding: content/BERT1/variables/ (stored 0%)\n",
            "  adding: content/BERT1/variables/variables.index (deflated 82%)\n",
            "  adding: content/BERT1/variables/variables.data-00000-of-00001 (deflated 14%)\n",
            "  adding: content/BERT2/ (stored 0%)\n",
            "  adding: content/BERT2/assets/ (stored 0%)\n",
            "  adding: content/BERT2/assets/vocab.txt (deflated 53%)\n",
            "  adding: content/BERT2/saved_model.pb (deflated 93%)\n",
            "  adding: content/BERT2/variables/ (stored 0%)\n",
            "  adding: content/BERT2/variables/variables.index (deflated 82%)\n",
            "  adding: content/BERT2/variables/variables.data-00000-of-00001 (deflated 14%)\n",
            "  adding: content/BERT3/ (stored 0%)\n",
            "  adding: content/BERT3/assets/ (stored 0%)\n",
            "  adding: content/BERT3/assets/vocab.txt (deflated 53%)\n",
            "  adding: content/BERT3/saved_model.pb (deflated 93%)\n",
            "  adding: content/BERT3/variables/ (stored 0%)\n",
            "  adding: content/BERT3/variables/variables.index (deflated 82%)\n",
            "  adding: content/BERT3/variables/variables.data-00000-of-00001 (deflated 14%)\n",
            "  adding: content/BERT4/ (stored 0%)\n",
            "  adding: content/BERT4/assets/ (stored 0%)\n",
            "  adding: content/BERT4/assets/vocab.txt (deflated 53%)\n",
            "  adding: content/BERT4/saved_model.pb (deflated 93%)\n",
            "  adding: content/BERT4/variables/ (stored 0%)\n",
            "  adding: content/BERT4/variables/variables.index (deflated 82%)\n",
            "  adding: content/BERT4/variables/variables.data-00000-of-00001 (deflated 14%)\n",
            "  adding: content/BERT5/ (stored 0%)\n",
            "  adding: content/BERT5/assets/ (stored 0%)\n",
            "  adding: content/BERT5/assets/vocab.txt (deflated 53%)\n",
            "  adding: content/BERT5/saved_model.pb (deflated 93%)\n",
            "  adding: content/BERT5/variables/ (stored 0%)\n",
            "  adding: content/BERT5/variables/variables.index (deflated 82%)\n",
            "  adding: content/BERT5/variables/variables.data-00000-of-00001 (deflated 14%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxvXTdRqpg_c"
      },
      "source": [
        "filepath = ''\n",
        "loaded_model = tf.keras.models.load_model(filepath)\n",
        "pred = np.argmax(model.predict(testdata), axis=-1)\n",
        "print(pred)\n",
        "pred2 = np.argmax(loaded_model.predict(testdata), axis=-1)\n",
        "print(pred)\n",
        "print(classification_report(pred,pred2,target_names= sentiment))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}